{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelo de Recomendação**\n",
    "Nesse notebok será trabalhado no modelo de recomendação de produtos com dados de usuários de Olist, que foram selecionados e gerados a partir do notebook **analise_exploratoria_olist.ipnyb** (recomendo a leitura). Além de treinarmos o modelo para recomendação, vamos validar sua qualidade de previsão, testar dados absolutos e normalizados, e alguns modelos para entender qual seria a melhor opção para essa base de dados.\n",
    "\n",
    "## **Resumo do Modelo**\n",
    "AAAAAAAAAAAAAAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas Necessárias para o modelo de recomendação\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split, GridSearchCV \n",
    "from surprise import accuracy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_mean</th>\n",
       "      <th>user_reviews_count</th>\n",
       "      <th>normalized_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>7c396fd4830fd04220f754e42b4e5bff</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>af07308b275d755c9edb36a90c618231</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>3a653a41f6f9fc3d2a113cf8398680e8</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>7c142cf63193a1473d2e66489a9ae977</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>72632f0f9dd73dfee390c9b22eb56dd6</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         product_id                           user_id  rating  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  7c396fd4830fd04220f754e42b4e5bff       4   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  af07308b275d755c9edb36a90c618231       4   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  3a653a41f6f9fc3d2a113cf8398680e8       5   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  7c142cf63193a1473d2e66489a9ae977       5   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  72632f0f9dd73dfee390c9b22eb56dd6       5   \n",
       "\n",
       "   user_mean  user_reviews_count  normalized_rating  \n",
       "0        4.5                   2               -0.5  \n",
       "1        4.0                   1                0.0  \n",
       "2        5.0                   1                0.0  \n",
       "3        5.0                   1                0.0  \n",
       "4        5.0                   1                0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel(\"df_produtos_avaliacoes.xlsx\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Treino e Teste**\n",
    "AAA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Carecterísticas do Modelo**\n",
    "A biblioteca Surprise fornece a possibilidade da configuração de hiper-parâmetros para encontrarmos de uma maneira mais simples a configuração ideal através da função **GridSerachCV**. A partir dessa função, podemos colocar um array de valores para os hiper-parâmetros **n_factors**, **lr_all** e **reg_all**.\n",
    "\n",
    "**n_factors**: Trata sobre a consideração de carecrísticas não vísiveis dos usuários que não estão no modelo.\n",
    "- Entre 10 à 30 características ocultas é aplicado para modelos mais simples e diminuindo a chance de overfitting do modelo.\n",
    "- Acima de 100 é aplicado para modelo mais complexos e pode aumentar a possibilidade overfitting para bases de dados pequenas.\n",
    "\n",
    "**lr_all**: Taxa de aprendizado do modelo, controla o tamanho dos passos que o modelo segue durante o treino. Esse parâmetro é o que \"ajusta\" os pesos a cada iteração.\n",
    "- Aplicando um valor baixo, como 0.002, o treino do modelo é mais lento, porém é considerado mais estável.\n",
    "- Aplicando um valor alto, como 0.01, o treino do modelo é mais rápido, porém pode oscilar.\n",
    "\n",
    "**reg_all**: Esse parâmetro é o que \"penaliza\", em maior ou menor peso, a previsão de dados mais distoantes. Esse parâmetro auxília para evitar o overfitting do modelo.\n",
    "- Aplicando um valor baixo, como 0.02, há pouca penalização, aumento a possibilidade de overfitting.\n",
    "- Aplicando um valor alto, como 0.01, há mais penalização, podendo substimar relações reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5)) #Definindo a escala das notas e a função de leitura da lib\n",
    "data_abs = Dataset.load_from_df(dataset[['user_id', 'product_id', 'rating']], reader) # Nota absoluta\n",
    "data_nor = Dataset.load_from_df(dataset[['user_id', 'product_id', 'normalized_rating']], reader) #Nota normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição dos hiper-parâmetros\n",
    "param_grid = {\n",
    "    'n_factors': [10, 30, 50, 125, 150],\n",
    "    'lr_all': [0.005, 0.008, 0.009, 0.01, 0.02],\n",
    "    'reg_all': [0.05, 0.075, 0.1, 0.15, 0.2]\n",
    "}\n",
    "\n",
    "#Definição das carecterísticas do modelo\n",
    "gs = GridSearchCV(SVD, #Modelo\n",
    "                  param_grid, #Hiper parâmetros\n",
    "                  measures=['rmse', 'mae'], #Métricas de Avaliação\n",
    "                  cv=5, #Qtd de recortes na bases de dados \n",
    "                  joblib_verbose=2) # Controle do nível de verbosidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos como SVD, SVD++, e BaselineOnly funcionam melhor quando os dados foram centrados em torno de médias.\n",
    "\n",
    "O SVD, por exemplo, decompõe a matriz de interações — se as notas estiverem normalizadas, a decomposição converge melhor e capta padrões reais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=1)]: Done 364 tasks      | elapsed:  4.4min\n"
     ]
    }
   ],
   "source": [
    "gs.fit(data_abs) #Treino com as notas absolutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE {'n_factors': 10, 'lr_all': 0.02, 'reg_all': 0.1}\n",
      "RMSE Score: 1.2546\n",
      "\n",
      "MAE {'n_factors': 10, 'lr_all': 0.02, 'reg_all': 0.05}\n",
      "MAE Score: 0.9699\n"
     ]
    }
   ],
   "source": [
    "#Verificação dos melhores hiper-parâmetros e algumas métricas de avaliação\n",
    "print('RMSE', gs.best_params['rmse'])\n",
    "print(f\"RMSE Score: {gs.best_score['rmse']:.4f}\")\n",
    "print('\\nMAE', gs.best_params['mae'])\n",
    "print(f\"MAE Score: {gs.best_score['mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=1)]: Done 364 tasks      | elapsed:  4.4min\n"
     ]
    }
   ],
   "source": [
    "gs.fit(data_nor) #Treino com as notas normalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE {'n_factors': 10, 'lr_all': 0.005, 'reg_all': 0.05}\n",
      "RMSE Score: 1.0137\n",
      "\n",
      "MAE {'n_factors': 10, 'lr_all': 0.005, 'reg_all': 0.05}\n",
      "MAE Score: 1.0048\n"
     ]
    }
   ],
   "source": [
    "#Verificação dos melhores hiper-parâmetros e algumas métricas de avaliação\n",
    "print('RMSE', gs.best_params['rmse'])\n",
    "print(f\"RMSE Score: {gs.best_score['rmse']:.4f}\")\n",
    "print('\\nMAE', gs.best_params['mae'])\n",
    "print(f\"MAE Score: {gs.best_score['mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Após realizar o treino com vários valores para parâmetros, chegou o momento de verificar, com base no resultado do RMSE e o MAE, quais valores dos hiper parâmetros são os mais ideais para gerar um modelo de recomendação de maior qualidade de previsão.\n",
    "\n",
    "Antes de verificar os melhores valores para os hiper parâmetros, vamos relembrar o que significa o RMSE e o MAE que vamos usar como base para essa escolha:\n",
    "\n",
    "<span style=\"font-size:20px\">**Root Mean Squared Error (RMSE)**</span>\n",
    "\n",
    "Essa métrica mede o erro médio ao quadrado entre o valor previsto e o valor real, auxilia no entendimento de quando o modelo pode cometer erros mais altos de previsão.\n",
    "\n",
    "<span style=\"font-size:20px\">**Mean Absolute Error (MAE)**</span>\n",
    "\n",
    "Essa métrica mede a diferença absoluta média entre o valor previsto e o valor real, auxilia no entendimento da qualidade do modelo em prever os valores reais.\n",
    "\n",
    "\n",
    "**Interpretação**\n",
    "\n",
    "Para esse caso, que temos notas de produtos entre 1 e 5, poderiamos interpretar o RMSE e o MAE da seguinte forma:\n",
    "\n",
    "Abaixo 0.7 - Excelente | Entre 0.7 e 0.9 - Bom | Entre 0.9 e 1.1 - Ok | Acima de 1.1 - Ruim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Treino, Teste e Validação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: nan\n",
      "RMSE no teste: nan\n",
      "MAE:  nan\n",
      "MAE no teste: nan\n"
     ]
    }
   ],
   "source": [
    "# Divisão dos dados\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Modelo com os melhores parâmetros\n",
    "best_model = gs.best_estimator['rmse']\n",
    "best_model.fit(trainset)\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "predictions = best_model.test(testset)\n",
    "print(\"RMSE no teste:\", accuracy.rmse(predictions))\n",
    "print(\"MAE no teste:\", accuracy.mae(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f1_at_k(predictions, k=3, threshold=4.0):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "        \n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for est_true in user_est_true.values():\n",
    "        est_true.sort(key=lambda x: x[0], reverse=True)\n",
    "        top_k = est_true[:k]\n",
    "        tp = sum((true_r >= threshold) for _, true_r in top_k)\n",
    "        fp = k - tp\n",
    "        fn = sum((true_r >= threshold) for _, true_r in est_true[k:])\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    return {\n",
    "        'Precision': sum(precisions) / len(precisions),\n",
    "        'Recall': sum(recalls) / len(recalls),\n",
    "        'F1': sum(f1s) / len(f1s)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas Top-N: {'Precision': 0.265147721582319, 'Recall': 0.7871877260334947, 'F1': 0.395999554887888}\n"
     ]
    }
   ],
   "source": [
    "metrics = precision_recall_f1_at_k(predictions, k=3)\n",
    "print(\"Métricas Top-N:\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treino com todos os dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1bdbf123c50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinar com 100% dos dados\n",
    "trainset_full = data.build_full_trainset()\n",
    "best_model.fit(trainset_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 recomendações para o usuário 345ecd01c38d18a9036ed96c73b8d066:\n",
      "Item 0 - Nota prevista: 5.00\n",
      "Item 1 - Nota prevista: 5.00\n",
      "Item 2 - Nota prevista: 5.00\n"
     ]
    }
   ],
   "source": [
    "# Treinar com 100% dos dados\n",
    "trainset_full = data.build_full_trainset()\n",
    "best_model.fit(trainset_full)\n",
    "\n",
    "# Recomendação para usuário 1: itens que ele ainda não avaliou\n",
    "user_id = \"345ecd01c38d18a9036ed96c73b8d066\"\n",
    "all_items = set(iid for (_, iid, _) in trainset_full.all_ratings())\n",
    "rated_items = set(j for (j, _) in trainset_full.ur[trainset_full.to_inner_uid(user_id)])\n",
    "unseen_items = all_items - rated_items\n",
    "\n",
    "# Predizer e ordenar por melhor nota prevista\n",
    "recommendations = [\n",
    "    (iid, best_model.predict(user_id, iid).est) for iid in unseen_items\n",
    "]\n",
    "recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Top 3 recomendações\n",
    "print(f\"Top 3 recomendações para o usuário {user_id}:\")\n",
    "for iid, score in recommendations[:3]:\n",
    "    print(f\"Item {iid} - Nota prevista: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Exemplo: Recomendação para o usuário 1\u001b[39;00m\n\u001b[0;32m     23\u001b[0m user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 24\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m recomendar_produtos(user_id, \u001b[43mdf\u001b[49m, model)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRecomendações para o usuário \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m product, rating \u001b[38;5;129;01min\u001b[39;00m recommendations:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Função para recomendar produtos a um usuário específico\n",
    "def recomendar_produtos(user_id, df, model, n_recommendations=3):\n",
    "    \"\"\"Gera recomendações de produtos para um usuário.\"\"\"\n",
    "    \n",
    "    # Obtém todos os produtos únicos\n",
    "    all_products = df['product_id'].unique()\n",
    "    \n",
    "    # Obtém produtos já avaliados pelo usuário\n",
    "    rated_products = df[df['user_id'] == user_id]['product_id'].values\n",
    "    \n",
    "    # Filtra apenas os produtos que o usuário ainda não avaliou\n",
    "    products_to_predict = [p for p in all_products if p not in rated_products]\n",
    "    \n",
    "    # Faz previsões para esses produtos\n",
    "    predictions = [(p, model.predict(user_id, p).est) for p in products_to_predict]\n",
    "    \n",
    "    # Ordena por nota prevista (maior para menor)\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return predictions[:n_recommendations]\n",
    "\n",
    "# Exemplo: Recomendação para o usuário 1\n",
    "user_id = 1\n",
    "recommendations = recomendar_produtos(user_id, df, model)\n",
    "\n",
    "print(f\"\\nRecomendações para o usuário {user_id}:\")\n",
    "for product, rating in recommendations:\n",
    "    print(f\"Produto {product} - Nota prevista: {rating:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendação de Produtos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separação dos dados para recomendação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ultima_compra = dataframe.groupby(\"customer_unique_id\").agg({'order_purchase_timestamp':max})\n",
    "df_ultima_compra.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ultima_compra['order_purchase_timestamp'] = pd.to_datetime(df_ultima_compra['order_purchase_timestamp'])\n",
    "data_referencia = pd.to_datetime('2018-09-10')\n",
    "df_ultima_compra['dias_desde_da_ultima_compra'] = (data_referencia - df_ultima_compra['order_purchase_timestamp']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30_90_dias = df_ultima_compra[(df_ultima_compra['dias_desde_da_ultima_compra'] >= 30) & (df_ultima_compra['dias_desde_da_ultima_compra'] <= 90)]['customer_unique_id']\n",
    "df_30_90_dias = df_30_90_dias.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
