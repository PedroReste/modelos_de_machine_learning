{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo - Treino e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importações**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas Necessárias para o modelo de recomendação\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split, GridSearchCV \n",
    "from surprise import accuracy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento das bases (o link dos arquivos estão no READ.md)\n",
    "olist_customers = pd.read_csv(\"olist_customers_dataset.csv\", sep=\",\")\n",
    "olist_orders = pd.read_csv(\"olist_orders_dataset.csv\", sep=\",\")\n",
    "olist_order_payments = pd.read_csv(\"olist_order_payments_dataset.csv\", sep=\",\")\n",
    "olist_order_reviews = pd.read_csv(\"olist_order_reviews_dataset.csv\", sep=\",\")\n",
    "olist_order_items = pd.read_csv(\"olist_order_items_dataset.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntando todas as bases\n",
    "dataframe = olist_customers.merge(olist_orders, on=\"customer_id\") \\\n",
    "                           .merge(olist_order_payments, on=\"order_id\") \\\n",
    "                           .merge(olist_order_reviews, on=\"order_id\") \\\n",
    "                           .merge(olist_order_items, on=\"order_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px\">**Filtro de Dados Utilizados no Modelo de Recomendação**</span>\n",
    "\n",
    "Esse momento, optei por filtrar do DataFrame original apenas os pedidos que foram entregues para os consumidores. Essa decisão é pelo entendimento que outros status como **não entregues, a caminho ou pgto efutuado** possuiam notas e poderiam atrapalhar o modelo de recomendação de produtos que foram recebido e devidametne avaliados.\n",
    "\n",
    "Também nessa seleção, precisamos apenas das colunas do ID dos usuários, ID do produto e a avaliação das ao produto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
       "      <td>a9516a079e37a9c9c36b9b78b10169e8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
       "      <td>4aa6014eceb682077f9dc4bffebc05b0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
       "      <td>bd07b66896d6f1494f5b86251848ced7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259dac757896d24d7702b9acbbff3f3c</td>\n",
       "      <td>a5647c44af977b148e0a3a4751a09e2e</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n",
       "      <td>9391a573abe00141c56e38d84d7d5b3b</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 customer_unique_id                        product_id  \\\n",
       "0  861eff4711a542e4b93843c6dd7febb0  a9516a079e37a9c9c36b9b78b10169e8   \n",
       "1  290c77bc529b7ac935b93aa66c333dc3  4aa6014eceb682077f9dc4bffebc05b0   \n",
       "2  060e732b5b29e8181a18229c7b0b2b5e  bd07b66896d6f1494f5b86251848ced7   \n",
       "3  259dac757896d24d7702b9acbbff3f3c  a5647c44af977b148e0a3a4751a09e2e   \n",
       "4  345ecd01c38d18a9036ed96c73b8d066  9391a573abe00141c56e38d84d7d5b3b   \n",
       "\n",
       "   review_score  \n",
       "0             4  \n",
       "1             5  \n",
       "2             5  \n",
       "3             5  \n",
       "4             5  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recom = dataframe[dataframe['order_status'] == 'delivered'][['customer_unique_id', 'product_id', 'review_score']]\n",
    "df_recom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_unique_id  product_id  review_score\n",
       "False               False       False           114859\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando se há valores vazios\n",
    "df_recom.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando o nome das colunas\n",
    "df_recom.rename(columns={\n",
    "    'customer_unique_id':'user_id',\n",
    "    'product_id':'product_id',\n",
    "    'review_score':'rating'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recom['user_mean'] = df_recom.groupby('user_id')['rating'].transform('mean')\n",
    "df_recom['user_reviews_count'] = df_recom.groupby('user_id')['rating'].transform('count')\n",
    "df_recom['normalized_rating'] = df_recom['rating'] - df_recom['user_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recom_reviw_1 = df_recom[df_recom['user_reviews_count'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qtd_avaliacoes</th>\n",
       "      <th>qtd_usuarios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>78803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qtd_avaliacoes  qtd_usuarios\n",
       "0                1         78803\n",
       "1                2         10170\n",
       "2                3          1970\n",
       "3                4           944\n",
       "4                5           328\n",
       "5                6           289\n",
       "6                7            70\n",
       "7                8            46\n",
       "8                9            24\n",
       "9               10            25\n",
       "10              11            18\n",
       "11              12            26\n",
       "12              13             5\n",
       "13              14             8\n",
       "14              15             7\n",
       "15              16             1\n",
       "16              18             1\n",
       "17              19             1\n",
       "18              20             3\n",
       "19              21             3\n",
       "20              22             1\n",
       "21              24             7\n",
       "22              26             1\n",
       "23              35             1\n",
       "24              38             1\n",
       "25              75             1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avaliacoes_por_user_id = df_recom['user_id'].value_counts()\n",
    "usuarios_por_qtd_avaliacoes = avaliacoes_por_user_id.value_counts().sort_index()\n",
    "usuarios_por_qtd_avaliacoes_df = pd.DataFrame({\n",
    "    'qtd_avaliacoes': usuarios_por_qtd_avaliacoes.index,\n",
    "    'qtd_usuarios': usuarios_por_qtd_avaliacoes.values\n",
    "})\n",
    "usuarios_por_qtd_avaliacoes_df.columns = ['qtd_avaliacoes', 'qtd_usuarios']\n",
    "usuarios_por_qtd_avaliacoes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo a leitura e carregamento dos dados para o formato da lib Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_recom[['user_id', 'product_id', 'rating']], reader)\n",
    "data_normalized = Dataset.load_from_df(df_recom[['user_id', 'product_id', 'normalized_rating']], reader)\n",
    "data_normalized_1 = Dataset.load_from_df(df_recom_reviw_1[['user_id', 'product_id', 'normalized_rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px\">**Configurando Melhores Carecterísticas do Modelo**</span>\n",
    "\n",
    "A biblioteca Surprise tem uma função bastante interessante nos deixa escolher alguns hiper parâmetros que nos auxiliam a encontrar a melhor configuração para o modelo de configuração através da função **GridSearchCV**. Os hiper parâmetros que podem ser definidos:\n",
    "\n",
    "<span style=\"font-size:20px\">**n_factors**</span>\n",
    "\n",
    "Trata sobre a consideração de carecrísticas não vísiveis dos usuários que não estão no modelo.\n",
    "- Entre 10 à 30 características ocultas é aplicado para modelos mais simples e diminuindo a chance de overfitting do modelo.\n",
    "- Acima de 100 é aplicado para modelo mais complexos e pode aumentar a possibildiade overfitting para bases de dados pequenas.\n",
    "\n",
    "<span style=\"font-size:20px\">**lr_all**</span>\n",
    "\n",
    "Taxa de aprendizado do modelo, controla o tamanho dos passos que o modelo segue durante o treino. Esse parâmetro é o que \"ajusta\" os pesos a cada iteração.\n",
    "- Aplicando um valor baixo, como 0.002, o treino do modelo é mais lento, porém é considerado mais estável.\n",
    "- Aplicando um valor alto, como 0.01, o treino do modelo é mais rápido, porém pode oscilar.\n",
    "\n",
    "<span style=\"font-size:20px\">**reg_all**</span>\n",
    "\n",
    "Esse parâmetro é o que \"penaliza\", em maior ou menor peso, a previsão de dados mais distoantes. Esse parâmetro auxília para evitar o overfitting do modelo.\n",
    "- Aplicando um valor baixo, como 0.02, há pouca penalização, aumento a possibilidade de overfitting.\n",
    "- Aplicando um valor alto, como 0.01, há mais penalização, podendo substimar relações reais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apenas usuários com pelo menos 5 avaliações?\n",
    "# Qtd Média de avaliação por usuário\n",
    "# Normalizar notas por usuário?\n",
    "\n",
    "Modelos como SVD, SVD++, e BaselineOnly funcionam melhor quando os dados foram centrados em torno de médias.\n",
    "\n",
    "O SVD, por exemplo, decompõe a matriz de interações — se as notas estiverem normalizadas, a decomposição converge melhor e capta padrões reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=1)]: Done 364 tasks      | elapsed:  9.7min\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [50, 100, 125, 150],\n",
    "    'lr_all': [0.005, 0.008, 0.009, 0.01, 0.02],\n",
    "    'reg_all': [0.05, 0.075, 0.1, 0.15, 0.2]\n",
    "}\n",
    "gs = GridSearchCV(SVD, #Modelo\n",
    "                  param_grid, #Hiper parâmetros\n",
    "                  measures=['rmse', 'mae'], #Métricas de Avaliação\n",
    "                  cv=5, #Qtd de recortes na bases de dados \n",
    "                  joblib_verbose=2) # Controle do nível de verbosidade\n",
    "gs.fit(data) #Treino para encontrar os melhos parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE {'n_factors': 150, 'lr_all': 0.02, 'reg_all': 0.075}\n",
      "RMSE Score: 1.1370\n",
      "\n",
      "MAE {'n_factors': 150, 'lr_all': 0.02, 'reg_all': 0.05}\n",
      "MAE Score: 0.8262\n"
     ]
    }
   ],
   "source": [
    "print('RMSE', gs.best_params['rmse'])\n",
    "print(f\"RMSE Score: {gs.best_score['rmse']:.4f}\")\n",
    "print('\\nMAE', gs.best_params['mae'])\n",
    "print(f\"MAE Score: {gs.best_score['mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=1)]: Done 364 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=1)]: Done 1012 tasks      | elapsed: 16.1min\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [1, 2, 5, 10, 50, 100],\n",
    "    'lr_all': [0.0005, 0.001, 0.0015, 0.002, 0.005, 0.01],\n",
    "    'reg_all': [0.01, 0.015, 0.02, 0.025, 0.05, 0.1]\n",
    "}\n",
    "gs = GridSearchCV(SVD, #Modelo\n",
    "                  param_grid, #Hiper parâmetros\n",
    "                  measures=['rmse', 'mae'], #Métricas de Avaliação\n",
    "                  cv=5, #Qtd de recortes na bases de dados \n",
    "                  joblib_verbose=2) # Controle do nível de verbosidade\n",
    "gs.fit(data_normalized) #Treino para encontrar os melhos parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE {'n_factors': 1, 'lr_all': 0.0005, 'reg_all': 0.01}\n",
      "RMSE Score: 1.0175\n",
      "\n",
      "MAE {'n_factors': 100, 'lr_all': 0.005, 'reg_all': 0.01}\n",
      "MAE Score: 1.0065\n"
     ]
    }
   ],
   "source": [
    "print('RMSE', gs.best_params['rmse'])\n",
    "print(f\"RMSE Score: {gs.best_score['rmse']:.4f}\")\n",
    "print('\\nMAE', gs.best_params['mae'])\n",
    "print(f\"MAE Score: {gs.best_score['mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=1)]: Done 364 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=1)]: Done 1012 tasks      | elapsed:  4.8min\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [1, 2, 5, 10, 50, 100],\n",
    "    'lr_all': [0.0005, 0.001, 0.0015, 0.002, 0.005, 0.01],\n",
    "    'reg_all': [0.01, 0.015, 0.02, 0.025, 0.05, 0.1]\n",
    "}\n",
    "gs = GridSearchCV(SVD, #Modelo\n",
    "                  param_grid, #Hiper parâmetros\n",
    "                  measures=['rmse', 'mae'], #Métricas de Avaliação\n",
    "                  cv=5, #Qtd de recortes na bases de dados \n",
    "                  joblib_verbose=2) # Controle do nível de verbosidade\n",
    "gs.fit(data_normalized_1) #Treino para encontrar os melhos parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE {'n_factors': 1, 'lr_all': 0.0005, 'reg_all': 0.01}\n",
      "RMSE Score: 1.0548\n",
      "\n",
      "MAE {'n_factors': 100, 'lr_all': 0.005, 'reg_all': 0.01}\n",
      "MAE Score: 1.0208\n"
     ]
    }
   ],
   "source": [
    "print('RMSE', gs.best_params['rmse'])\n",
    "print(f\"RMSE Score: {gs.best_score['rmse']:.4f}\")\n",
    "print('\\nMAE', gs.best_params['mae'])\n",
    "print(f\"MAE Score: {gs.best_score['mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após realizar o treino com vários valores para parâmetros, chegou o momento de verificar, com base no resultado do RMSE e o MAE, quais valores dos hiper parâmetros são os mais ideais para gerar um modelo de recomendação de maior qualidade de previsão.\n",
    "\n",
    "Antes de verificar os melhores valores para os hiper parâmetros, vamos relembrar o que significa o RMSE e o MAE que vamos usar como base para essa escolha:\n",
    "\n",
    "<span style=\"font-size:20px\">**Root Mean Squared Error (RMSE)**</span>\n",
    "\n",
    "Essa métrica mede o erro médio ao quadrado entre o valor previsto e o valor real, auxilia no entendimento de quando o modelo pode cometer erros mais altos de previsão.\n",
    "\n",
    "<span style=\"font-size:20px\">**Mean Absolute Error (MAE)**</span>\n",
    "\n",
    "Essa métrica mede a diferença absoluta média entre o valor previsto e o valor real, auxilia no entendimento da qualidade do modelo em prever os valores reais.\n",
    "\n",
    "\n",
    "**Interpretação**\n",
    "\n",
    "Para esse caso, que temos notas de produtos entre 1 e 5, poderiamos interpretar o RMSE e o MAE da seguinte forma:\n",
    "\n",
    "Abaixo 0.7 - Excelente | Entre 0.7 e 0.9 - Bom | Entre 0.9 e 1.1 - Ok | Acima de 1.1 - Ruim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treino, Teste e Validação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1667\n",
      "RMSE no teste: 1.1667449742755942\n",
      "MAE:  0.8811\n",
      "MAE no teste: 0.8810697263300789\n"
     ]
    }
   ],
   "source": [
    "# Divisão dos dados\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Modelo com os melhores parâmetros\n",
    "best_model = gs.best_estimator['rmse']\n",
    "best_model.fit(trainset)\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "predictions = best_model.test(testset)\n",
    "print(\"RMSE no teste:\", accuracy.rmse(predictions))\n",
    "print(\"MAE no teste:\", accuracy.mae(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f1_at_k(predictions, k=3, threshold=4.0):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "        \n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for est_true in user_est_true.values():\n",
    "        est_true.sort(key=lambda x: x[0], reverse=True)\n",
    "        top_k = est_true[:k]\n",
    "        tp = sum((true_r >= threshold) for _, true_r in top_k)\n",
    "        fp = k - tp\n",
    "        fn = sum((true_r >= threshold) for _, true_r in est_true[k:])\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    return {\n",
    "        'Precision': sum(precisions) / len(precisions),\n",
    "        'Recall': sum(recalls) / len(recalls),\n",
    "        'F1': sum(f1s) / len(f1s)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas Top-N: {'Precision': 0.2741800566811954, 'Recall': 0.7766103223850972, 'F1': 0.4011694343335997}\n"
     ]
    }
   ],
   "source": [
    "metrics = precision_recall_f1_at_k(predictions, k=3)\n",
    "print(\"Métricas Top-N:\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treino com todos os dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x283f9dafc90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinar com 100% dos dados\n",
    "trainset_full = data.build_full_trainset()\n",
    "best_model.fit(trainset_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 recomendações para o usuário 345ecd01c38d18a9036ed96c73b8d066:\n",
      "Item 0 - Nota prevista: 4.23\n",
      "Item 1 - Nota prevista: 4.23\n",
      "Item 2 - Nota prevista: 4.23\n"
     ]
    }
   ],
   "source": [
    "# Treinar com 100% dos dados\n",
    "trainset_full = data.build_full_trainset()\n",
    "best_model.fit(trainset_full)\n",
    "\n",
    "# Recomendação para usuário 1: itens que ele ainda não avaliou\n",
    "user_id = \"345ecd01c38d18a9036ed96c73b8d066\"\n",
    "all_items = set(iid for (_, iid, _) in trainset_full.all_ratings())\n",
    "rated_items = set(j for (j, _) in trainset_full.ur[trainset_full.to_inner_uid(user_id)])\n",
    "unseen_items = all_items - rated_items\n",
    "\n",
    "# Predizer e ordenar por melhor nota prevista\n",
    "recommendations = [\n",
    "    (iid, best_model.predict(user_id, iid).est) for iid in unseen_items\n",
    "]\n",
    "recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Top 3 recomendações\n",
    "print(f\"Top 3 recomendações para o usuário {user_id}:\")\n",
    "for iid, score in recommendations[:3]:\n",
    "    print(f\"Item {iid} - Nota prevista: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Exemplo: Recomendação para o usuário 1\u001b[39;00m\n\u001b[0;32m     23\u001b[0m user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 24\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m recomendar_produtos(user_id, \u001b[43mdf\u001b[49m, model)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRecomendações para o usuário \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m product, rating \u001b[38;5;129;01min\u001b[39;00m recommendations:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Função para recomendar produtos a um usuário específico\n",
    "def recomendar_produtos(user_id, df, model, n_recommendations=3):\n",
    "    \"\"\"Gera recomendações de produtos para um usuário.\"\"\"\n",
    "    \n",
    "    # Obtém todos os produtos únicos\n",
    "    all_products = df['product_id'].unique()\n",
    "    \n",
    "    # Obtém produtos já avaliados pelo usuário\n",
    "    rated_products = df[df['user_id'] == user_id]['product_id'].values\n",
    "    \n",
    "    # Filtra apenas os produtos que o usuário ainda não avaliou\n",
    "    products_to_predict = [p for p in all_products if p not in rated_products]\n",
    "    \n",
    "    # Faz previsões para esses produtos\n",
    "    predictions = [(p, model.predict(user_id, p).est) for p in products_to_predict]\n",
    "    \n",
    "    # Ordena por nota prevista (maior para menor)\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return predictions[:n_recommendations]\n",
    "\n",
    "# Exemplo: Recomendação para o usuário 1\n",
    "user_id = 1\n",
    "recommendations = recomendar_produtos(user_id, df, model)\n",
    "\n",
    "print(f\"\\nRecomendações para o usuário {user_id}:\")\n",
    "for product, rating in recommendations:\n",
    "    print(f\"Produto {product} - Nota prevista: {rating:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendação de Produtos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separação dos dados para recomendação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computador\\AppData\\Local\\Temp\\ipykernel_4784\\2487374714.py:1: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  df_ultima_compra = dataframe.groupby(\"customer_unique_id\").agg({'order_purchase_timestamp':max})\n"
     ]
    }
   ],
   "source": [
    "df_ultima_compra = dataframe.groupby(\"customer_unique_id\").agg({'order_purchase_timestamp':max})\n",
    "df_ultima_compra.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ultima_compra['order_purchase_timestamp'] = pd.to_datetime(df_ultima_compra['order_purchase_timestamp'])\n",
    "data_referencia = pd.to_datetime('2018-09-10')\n",
    "df_ultima_compra['dias_desde_da_ultima_compra'] = (data_referencia - df_ultima_compra['order_purchase_timestamp']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30_90_dias = df_ultima_compra[(df_ultima_compra['dias_desde_da_ultima_compra'] >= 30) & (df_ultima_compra['dias_desde_da_ultima_compra'] <= 90)]['customer_unique_id']\n",
    "df_30_90_dias = df_30_90_dias.to_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
