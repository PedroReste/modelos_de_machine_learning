{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo - Treino e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importações**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas Necessárias para o modelo de recomendação\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split, GridSearchCV \n",
    "from surprise import accuracy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento das bases (o link dos arquivos estão no READ.md)\n",
    "dataset = pd.read_csv(\"Reviews.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px\">**Filtro de Dados Utilizados no Modelo de Recomendação**</span>\n",
    "\n",
    "Esse momento, optei por filtrar do DataFrame original apenas os pedidos que foram entregues para os consumidores. Essa decisão é pelo entendimento que outros status como **não entregues, a caminho ou pgto efutuado** possuiam notas e poderiam atrapalhar o modelo de recomendação de produtos que foram recebido e devidametne avaliados.\n",
    "\n",
    "Também nessa seleção, precisamos apenas das colunas do ID dos usuários, ID do produto e a avaliação das ao produto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UserId   ProductId  Score\n",
       "0  A3SGXH7AUHU8GW  B001E4KFG0      5\n",
       "1  A1D87F6ZCVE5NK  B00813GRG4      1\n",
       "2   ABXLMWJIXXAIN  B000LQOCH0      4\n",
       "3  A395BORC6FGVXV  B000UA0QIQ      2\n",
       "4  A1UQRSCLF8GW1T  B006K2ZZ7K      5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recom = dataset[['UserId', 'ProductId', 'Score']]\n",
    "df_recom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserId  ProductId  Score\n",
       "False   False      False    568454\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando se há valores vazios\n",
    "df_recom.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computador\\AppData\\Local\\Temp\\ipykernel_14288\\2938545904.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recom.rename(columns={\n"
     ]
    }
   ],
   "source": [
    "# Renomeando o nome das colunas\n",
    "df_recom.rename(columns={\n",
    "    'UserId':'user_id',\n",
    "    'ProductId':'product_id',\n",
    "    'Score':'rating'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computador\\AppData\\Local\\Temp\\ipykernel_14288\\349433239.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recom['user_mean'] = df_recom.groupby('user_id')['rating'].transform('mean')\n",
      "C:\\Users\\Computador\\AppData\\Local\\Temp\\ipykernel_14288\\349433239.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recom['user_reviews_count'] = df_recom.groupby('user_id')['rating'].transform('count')\n",
      "C:\\Users\\Computador\\AppData\\Local\\Temp\\ipykernel_14288\\349433239.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recom['normalized_rating'] = df_recom['rating'] - df_recom['user_mean']\n"
     ]
    }
   ],
   "source": [
    "df_recom['user_mean'] = df_recom.groupby('user_id')['rating'].transform('mean')\n",
    "df_recom['user_reviews_count'] = df_recom.groupby('user_id')['rating'].transform('count')\n",
    "df_recom['normalized_rating'] = df_recom['rating'] - df_recom['user_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recom_reviw_1 = df_recom[df_recom['user_reviews_count'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qtd_avaliacoes</th>\n",
       "      <th>qtd_usuarios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>175391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>32658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     qtd_avaliacoes  qtd_usuarios\n",
       "0                 1        175391\n",
       "1                 2         32658\n",
       "2                 3         13828\n",
       "3                 4         10589\n",
       "4                 5          5417\n",
       "..              ...           ...\n",
       "139             256             1\n",
       "140             365             1\n",
       "141             389             1\n",
       "142             421             1\n",
       "143             448             1\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avaliacoes_por_user_id = df_recom['user_id'].value_counts()\n",
    "usuarios_por_qtd_avaliacoes = avaliacoes_por_user_id.value_counts().sort_index()\n",
    "usuarios_por_qtd_avaliacoes_df = pd.DataFrame({\n",
    "    'qtd_avaliacoes': usuarios_por_qtd_avaliacoes.index,\n",
    "    'qtd_usuarios': usuarios_por_qtd_avaliacoes.values\n",
    "})\n",
    "usuarios_por_qtd_avaliacoes_df.columns = ['qtd_avaliacoes', 'qtd_usuarios']\n",
    "usuarios_por_qtd_avaliacoes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo a leitura e carregamento dos dados para o formato da lib Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_recom[['user_id', 'product_id', 'rating']], reader)\n",
    "data_normalized = Dataset.load_from_df(df_recom[['user_id', 'product_id', 'normalized_rating']], reader)\n",
    "data_normalized_1 = Dataset.load_from_df(df_recom_reviw_1[['user_id', 'product_id', 'normalized_rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px\">**Configurando Melhores Carecterísticas do Modelo**</span>\n",
    "\n",
    "A biblioteca Surprise tem uma função bastante interessante nos deixa escolher alguns hiper parâmetros que nos auxiliam a encontrar a melhor configuração para o modelo de configuração através da função **GridSearchCV**. Os hiper parâmetros que podem ser definidos:\n",
    "\n",
    "<span style=\"font-size:20px\">**n_factors**</span>\n",
    "\n",
    "Trata sobre a consideração de carecrísticas não vísiveis dos usuários que não estão no modelo.\n",
    "- Entre 10 à 30 características ocultas é aplicado para modelos mais simples e diminuindo a chance de overfitting do modelo.\n",
    "- Acima de 100 é aplicado para modelo mais complexos e pode aumentar a possibildiade overfitting para bases de dados pequenas.\n",
    "\n",
    "<span style=\"font-size:20px\">**lr_all**</span>\n",
    "\n",
    "Taxa de aprendizado do modelo, controla o tamanho dos passos que o modelo segue durante o treino. Esse parâmetro é o que \"ajusta\" os pesos a cada iteração.\n",
    "- Aplicando um valor baixo, como 0.002, o treino do modelo é mais lento, porém é considerado mais estável.\n",
    "- Aplicando um valor alto, como 0.01, o treino do modelo é mais rápido, porém pode oscilar.\n",
    "\n",
    "<span style=\"font-size:20px\">**reg_all**</span>\n",
    "\n",
    "Esse parâmetro é o que \"penaliza\", em maior ou menor peso, a previsão de dados mais distoantes. Esse parâmetro auxília para evitar o overfitting do modelo.\n",
    "- Aplicando um valor baixo, como 0.02, há pouca penalização, aumento a possibilidade de overfitting.\n",
    "- Aplicando um valor alto, como 0.01, há mais penalização, podendo substimar relações reais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apenas usuários com pelo menos 5 avaliações?\n",
    "# Qtd Média de avaliação por usuário\n",
    "# Normalizar notas por usuário?\n",
    "\n",
    "Modelos como SVD, SVD++, e BaselineOnly funcionam melhor quando os dados foram centrados em torno de médias.\n",
    "\n",
    "O SVD, por exemplo, decompõe a matriz de interações — se as notas estiverem normalizadas, a decomposição converge melhor e capta padrões reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed: 17.1min\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [20, 50, 100, 150],\n",
    "    'lr_all': [0.002, 0.005, 0.01, 0.02],\n",
    "    'reg_all': [0.02, 0.05, 0.1, 0.2]\n",
    "}\n",
    "gs = GridSearchCV(SVD, #Modelo\n",
    "                  param_grid, #Hiper parâmetros\n",
    "                  measures=['rmse', 'mae'], #Métricas de Avaliação\n",
    "                  cv=5, #Qtd de recortes na bases de dados \n",
    "                  joblib_verbose=2) # Controle do nível de verbosidade\n",
    "gs.fit(data) #Treino para encontrar os melhos parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE {'n_factors': 50, 'lr_all': 0.02, 'reg_all': 0.02}\n",
      "RMSE Score: 1.0143\n",
      "\n",
      "MAE {'n_factors': 20, 'lr_all': 0.02, 'reg_all': 0.02}\n",
      "MAE Score: 0.6608\n"
     ]
    }
   ],
   "source": [
    "print('RMSE', gs.best_params['rmse'])\n",
    "print(f\"RMSE Score: {gs.best_score['rmse']:.4f}\")\n",
    "print('\\nMAE', gs.best_params['mae'])\n",
    "print(f\"MAE Score: {gs.best_score['mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed: 19.0min\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [20, 50, 100, 150],\n",
    "    'lr_all': [0.002, 0.005, 0.01, 0.02],\n",
    "    'reg_all': [0.02, 0.05, 0.1, 0.2]\n",
    "}\n",
    "gs = GridSearchCV(SVD, #Modelo\n",
    "                  param_grid, #Hiper parâmetros\n",
    "                  measures=['rmse', 'mae'], #Métricas de Avaliação\n",
    "                  cv=5, #Qtd de recortes na bases de dados \n",
    "                  joblib_verbose=2) # Controle do nível de verbosidade\n",
    "gs.fit(data_normalized) #Treino para encontrar os melhos parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE {'n_factors': 100, 'lr_all': 0.02, 'reg_all': 0.02}\n",
      "RMSE Score: 1.1671\n",
      "\n",
      "MAE {'n_factors': 100, 'lr_all': 0.02, 'reg_all': 0.02}\n",
      "MAE Score: 1.0414\n"
     ]
    }
   ],
   "source": [
    "print('RMSE', gs.best_params['rmse'])\n",
    "print(f\"RMSE Score: {gs.best_score['rmse']:.4f}\")\n",
    "print('\\nMAE', gs.best_params['mae'])\n",
    "print(f\"MAE Score: {gs.best_score['mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed: 13.2min\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [20, 50, 100, 150],\n",
    "    'lr_all': [0.002, 0.005, 0.01, 0.02],\n",
    "    'reg_all': [0.02, 0.05, 0.1, 0.2]\n",
    "}\n",
    "gs = GridSearchCV(SVD, #Modelo\n",
    "                  param_grid, #Hiper parâmetros\n",
    "                  measures=['rmse', 'mae'], #Métricas de Avaliação\n",
    "                  cv=5, #Qtd de recortes na bases de dados \n",
    "                  joblib_verbose=2) # Controle do nível de verbosidade\n",
    "gs.fit(data_normalized_1) #Treino para encontrar os melhos parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE {'n_factors': 100, 'lr_all': 0.01, 'reg_all': 0.05}\n",
      "RMSE Score: 1.2345\n",
      "\n",
      "MAE {'n_factors': 100, 'lr_all': 0.02, 'reg_all': 0.02}\n",
      "MAE Score: 1.0599\n"
     ]
    }
   ],
   "source": [
    "print('RMSE', gs.best_params['rmse'])\n",
    "print(f\"RMSE Score: {gs.best_score['rmse']:.4f}\")\n",
    "print('\\nMAE', gs.best_params['mae'])\n",
    "print(f\"MAE Score: {gs.best_score['mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após realizar o treino com vários valores para parâmetros, chegou o momento de verificar, com base no resultado do RMSE e o MAE, quais valores dos hiper parâmetros são os mais ideais para gerar um modelo de recomendação de maior qualidade de previsão.\n",
    "\n",
    "Antes de verificar os melhores valores para os hiper parâmetros, vamos relembrar o que significa o RMSE e o MAE que vamos usar como base para essa escolha:\n",
    "\n",
    "<span style=\"font-size:20px\">**Root Mean Squared Error (RMSE)**</span>\n",
    "\n",
    "Essa métrica mede o erro médio ao quadrado entre o valor previsto e o valor real, auxilia no entendimento de quando o modelo pode cometer erros mais altos de previsão.\n",
    "\n",
    "<span style=\"font-size:20px\">**Mean Absolute Error (MAE)**</span>\n",
    "\n",
    "Essa métrica mede a diferença absoluta média entre o valor previsto e o valor real, auxilia no entendimento da qualidade do modelo em prever os valores reais.\n",
    "\n",
    "\n",
    "**Interpretação**\n",
    "\n",
    "Para esse caso, que temos notas de produtos entre 1 e 5, poderiamos interpretar o RMSE e o MAE da seguinte forma:\n",
    "\n",
    "Abaixo 0.7 - Excelente | Entre 0.7 e 0.9 - Bom | Entre 0.9 e 1.1 - Ok | Acima de 1.1 - Ruim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treino, Teste e Validação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0495\n",
      "RMSE no teste: 1.0495183101279983\n",
      "MAE:  0.7397\n",
      "MAE no teste: 0.739711024465631\n"
     ]
    }
   ],
   "source": [
    "# Divisão dos dados\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Modelo com os melhores parâmetros\n",
    "best_model = gs.best_estimator['rmse']\n",
    "best_model.fit(trainset)\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "predictions = best_model.test(testset)\n",
    "print(\"RMSE no teste:\", accuracy.rmse(predictions))\n",
    "print(\"MAE no teste:\", accuracy.mae(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f1_at_k(predictions, k=3, threshold=4.0):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "        \n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for est_true in user_est_true.values():\n",
    "        est_true.sort(key=lambda x: x[0], reverse=True)\n",
    "        top_k = est_true[:k]\n",
    "        tp = sum((true_r >= threshold) for _, true_r in top_k)\n",
    "        fp = k - tp\n",
    "        fn = sum((true_r >= threshold) for _, true_r in est_true[k:])\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    return {\n",
    "        'Precision': sum(precisions) / len(precisions),\n",
    "        'Recall': sum(recalls) / len(recalls),\n",
    "        'F1': sum(f1s) / len(f1s)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas Top-N: {'Precision': 0.34921749491945675, 'Recall': 0.7816336653090029, 'F1': 0.4558086068168882}\n"
     ]
    }
   ],
   "source": [
    "metrics = precision_recall_f1_at_k(predictions, k=3)\n",
    "print(\"Métricas Top-N:\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treino com todos os dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x2d62e79f750>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinar com 100% dos dados\n",
    "trainset_full = data.build_full_trainset()\n",
    "best_model.fit(trainset_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "User 345ecd01c38d18a9036ed96c73b8d066 is not part of the trainset.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\surprise\\trainset.py:110\u001b[0m, in \u001b[0;36mTrainset.to_inner_uid\u001b[1;34m(self, ruid)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw2inner_id_users\u001b[49m\u001b[43m[\u001b[49m\u001b[43mruid\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: '345ecd01c38d18a9036ed96c73b8d066'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m345ecd01c38d18a9036ed96c73b8d066\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m all_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(iid \u001b[38;5;28;01mfor\u001b[39;00m (_, iid, _) \u001b[38;5;129;01min\u001b[39;00m trainset_full\u001b[38;5;241m.\u001b[39mall_ratings())\n\u001b[1;32m----> 8\u001b[0m rated_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(j \u001b[38;5;28;01mfor\u001b[39;00m (j, _) \u001b[38;5;129;01min\u001b[39;00m trainset_full\u001b[38;5;241m.\u001b[39mur[\u001b[43mtrainset_full\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_inner_uid\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[0;32m      9\u001b[0m unseen_items \u001b[38;5;241m=\u001b[39m all_items \u001b[38;5;241m-\u001b[39m rated_items\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Predizer e ordenar por melhor nota prevista\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\surprise\\trainset.py:112\u001b[0m, in \u001b[0;36mTrainset.to_inner_uid\u001b[1;34m(self, ruid)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw2inner_id_users[ruid]\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(ruid) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not part of the trainset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: User 345ecd01c38d18a9036ed96c73b8d066 is not part of the trainset."
     ]
    }
   ],
   "source": [
    "# Treinar com 100% dos dados\n",
    "trainset_full = data.build_full_trainset()\n",
    "best_model.fit(trainset_full)\n",
    "\n",
    "# Recomendação para usuário 1: itens que ele ainda não avaliou\n",
    "user_id = \"345ecd01c38d18a9036ed96c73b8d066\"\n",
    "all_items = set(iid for (_, iid, _) in trainset_full.all_ratings())\n",
    "rated_items = set(j for (j, _) in trainset_full.ur[trainset_full.to_inner_uid(user_id)])\n",
    "unseen_items = all_items - rated_items\n",
    "\n",
    "# Predizer e ordenar por melhor nota prevista\n",
    "recommendations = [\n",
    "    (iid, best_model.predict(user_id, iid).est) for iid in unseen_items\n",
    "]\n",
    "recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Top 3 recomendações\n",
    "print(f\"Top 3 recomendações para o usuário {user_id}:\")\n",
    "for iid, score in recommendations[:3]:\n",
    "    print(f\"Item {iid} - Nota prevista: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Exemplo: Recomendação para o usuário 1\u001b[39;00m\n\u001b[0;32m     23\u001b[0m user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 24\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m recomendar_produtos(user_id, \u001b[43mdf\u001b[49m, model)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRecomendações para o usuário \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m product, rating \u001b[38;5;129;01min\u001b[39;00m recommendations:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Função para recomendar produtos a um usuário específico\n",
    "def recomendar_produtos(user_id, df, model, n_recommendations=3):\n",
    "    \"\"\"Gera recomendações de produtos para um usuário.\"\"\"\n",
    "    \n",
    "    # Obtém todos os produtos únicos\n",
    "    all_products = df['product_id'].unique()\n",
    "    \n",
    "    # Obtém produtos já avaliados pelo usuário\n",
    "    rated_products = df[df['user_id'] == user_id]['product_id'].values\n",
    "    \n",
    "    # Filtra apenas os produtos que o usuário ainda não avaliou\n",
    "    products_to_predict = [p for p in all_products if p not in rated_products]\n",
    "    \n",
    "    # Faz previsões para esses produtos\n",
    "    predictions = [(p, model.predict(user_id, p).est) for p in products_to_predict]\n",
    "    \n",
    "    # Ordena por nota prevista (maior para menor)\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return predictions[:n_recommendations]\n",
    "\n",
    "# Exemplo: Recomendação para o usuário 1\n",
    "user_id = 1\n",
    "recommendations = recomendar_produtos(user_id, df, model)\n",
    "\n",
    "print(f\"\\nRecomendações para o usuário {user_id}:\")\n",
    "for product, rating in recommendations:\n",
    "    print(f\"Produto {product} - Nota prevista: {rating:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendação de Produtos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separação dos dados para recomendação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computador\\AppData\\Local\\Temp\\ipykernel_4784\\2487374714.py:1: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  df_ultima_compra = dataframe.groupby(\"customer_unique_id\").agg({'order_purchase_timestamp':max})\n"
     ]
    }
   ],
   "source": [
    "df_ultima_compra = dataframe.groupby(\"customer_unique_id\").agg({'order_purchase_timestamp':max})\n",
    "df_ultima_compra.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ultima_compra['order_purchase_timestamp'] = pd.to_datetime(df_ultima_compra['order_purchase_timestamp'])\n",
    "data_referencia = pd.to_datetime('2018-09-10')\n",
    "df_ultima_compra['dias_desde_da_ultima_compra'] = (data_referencia - df_ultima_compra['order_purchase_timestamp']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30_90_dias = df_ultima_compra[(df_ultima_compra['dias_desde_da_ultima_compra'] >= 30) & (df_ultima_compra['dias_desde_da_ultima_compra'] <= 90)]['customer_unique_id']\n",
    "df_30_90_dias = df_30_90_dias.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
