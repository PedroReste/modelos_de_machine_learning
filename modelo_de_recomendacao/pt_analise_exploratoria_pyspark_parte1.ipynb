{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80122a5c",
   "metadata": {},
   "source": [
    "# **Resumo da Análise Exploratória - Parte 01**\n",
    "Esse notebook aborda uma breve exploração de dados para comprender pontos principais dos dados e a viabilidade para gerar um modelo de recomendação de produtos.\n",
    "\n",
    "**Insights Gerados**\n",
    "- 90% dos pedidos tem um único produto e 96% possuem um único produto ou mais de um produto igual.\n",
    "- Como 96% da base consiste em pedidos com o mesmo produto, será possível utilizar o order_id como uma proxy para o produto, já que as bases da Olist não possuem a avalição feita por produto, mas apenas por pedido.\n",
    "- Aproximadamente 97% dos usuários fizeram um único pedido.\n",
    "- Numa escala de nota de 1 a 5: aproximadamente 12% dos usuários deram uma nota baixa para o produto (1 ou 2), 8% deram uma nota mediana (3) e 80% deram uma nota alta (4 ou 5).\n",
    "- Mesmo com 97% dos usuários tendo um pedido, vamos no modelo testar tanto o valor absoluto da média de notas quanto os valores normalizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a4ad000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"session\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\") #Otimização dinâmicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba7a357",
   "metadata": {},
   "source": [
    "---\n",
    "# **Convertendo os arquivos de CSV para Parquet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af5d084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando os arquivos em CSV com a função nativa do PySpark\n",
    "olist_customers = spark.read.option(\"header\", True).csv(\"olist_customers_dataset.csv\")\n",
    "olist_orders = spark.read.option(\"header\", True).csv(\"olist_orders_dataset.csv\")\n",
    "olist_order_reviews = spark.read.option(\"header\", True).csv(\"olist_order_reviews_dataset.csv\")\n",
    "olist_order_items = spark.read.option(\"header\", True).csv(\"olist_order_items_dataset.csv\")\n",
    "olist_products = spark.read.option(\"header\", True).csv(\"olist_products_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fc306b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo os dfs para Parquet\n",
    "olist_customers.write.mode(\"overwrite\").parquet(\"olist_customers_dataset.parquet\")\n",
    "olist_customers.write.mode(\"overwrite\").parquet(\"olist_customers_dataset.parquet\")\n",
    "olist_orders.write.mode(\"overwrite\").parquet(\"olist_orders_dataset.parquet\")\n",
    "olist_order_reviews.write.mode(\"overwrite\").parquet(\"olist_order_reviews_dataset.parquet\")\n",
    "olist_order_items.write.mode(\"overwrite\").parquet(\"olist_order_items_dataset.parquet\")\n",
    "olist_products.write.mode(\"overwrite\").parquet(\"olist_products_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "303e3c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando novamente os dfs, mas com a versão em Parquet\n",
    "olist_customers = spark.read.option(\"header\", True).parquet(\"olist_customers_dataset.parquet\") \\\n",
    "    .select('customer_id', 'customer_unique_id')\n",
    "olist_orders = spark.read.option(\"header\", True).parquet(\"olist_orders_dataset.parquet\") \\\n",
    "    .select('customer_id', 'order_id', 'order_status', 'order_purchase_timestamp')\n",
    "olist_order_reviews = spark.read.option(\"header\", True).parquet(\"olist_order_reviews_dataset.parquet\") \\\n",
    "    .select('order_id', 'review_score')\n",
    "olist_order_items = spark.read.option(\"header\", True).parquet(\"olist_order_items_dataset.parquet\") \\\n",
    "    .select('order_id', 'product_id')\n",
    "olist_products = spark.read.option(\"header\", True).parquet(\"olist_products_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfc7430",
   "metadata": {},
   "source": [
    "---\n",
    "# **Verificando a volumetria de pedidos e produtos de cada pedido**\n",
    "\n",
    "O dataset **olist_order_items** contém a lista de pedidos e seus itens com diversas informações, mas para nós nesse momento vai ser importante apenas as colunas de **order_id** e **product_id** de cada pedido realizado.\n",
    "\n",
    "Nessa seção do notebook, vamos verificar a volumetria de pedidos e entender alguns elementos principais, como: existem quantos itens por pedido? esses itens são iguais?\n",
    "\n",
    "Numa exploração anterior nos datasets da Olist, foi percebido que essas bases tem avaliação de satisfação por pedido e não produto. A intenção agora é comprender essas carecterísicas para validar a possibilidade de utilizar o **order_id** com uma proxy de **product_id** para gerar o modelo de recomendação de produtos para os clientes desse dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "422ab62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+-----------------------+\n",
      "|total|volumetria_pedidos|volumetria_pedidos_perc|\n",
      "+-----+------------------+-----------------------+\n",
      "|    1|             88863|                  90.06|\n",
      "|    2|              7516|                   7.62|\n",
      "|    3|              1322|                   1.34|\n",
      "|    4|               505|                   0.51|\n",
      "|    5|               204|                   0.21|\n",
      "+-----+------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+--------------------+-------------------------+\n",
      "|distinto|volumetria_distintos|volumetria_distintos_perc|\n",
      "+--------+--------------------+-------------------------+\n",
      "|       1|               95430|                    96.72|\n",
      "|       2|                2846|                     2.88|\n",
      "|       3|                 298|                      0.3|\n",
      "|       4|                  70|                     0.07|\n",
      "|       5|                   8|                     0.01|\n",
      "+--------+--------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Estrutura base para os cálculos\n",
    "produtos = olist_order_items.groupBy(\"order_id\").agg(\n",
    "    F.count(\"product_id\").alias(\"total\"),\n",
    "    F.countDistinct(\"product_id\").alias(\"distinto\")\n",
    ")\n",
    "\n",
    "#Visão total de pedidos\n",
    "volumetria = produtos.groupBy(\"total\").agg(F.count(\"*\").alias(\"volumetria_pedidos\"))\n",
    "total_pedidos = volumetria.agg({\"volumetria_pedidos\":\"sum\"}).collect()[0][0]\n",
    "\n",
    "volumetria = volumetria.withColumn(\n",
    "    \"volumetria_pedidos_perc\",\n",
    "    F.round((F.col(\"volumetria_pedidos\") / F.lit(total_pedidos)) * 100, 2)\n",
    ")\n",
    "volumetria.orderBy(\"total\").show(5)\n",
    "\n",
    "#Visão total distintos\n",
    "volumetria_distintos = produtos.groupBy(\"distinto\").agg(F.count(\"*\").alias(\"volumetria_distintos\"))\n",
    "total_distintos = volumetria_distintos.agg({\"volumetria_distintos\":\"sum\"}).collect()[0][0]\n",
    "\n",
    "volumetria_distintos = volumetria_distintos.withColumn(\n",
    "    \"volumetria_distintos_perc\",\n",
    "    F.round((F.col(\"volumetria_distintos\") / F.lit(total_distintos)) *100, 2)\n",
    ")\n",
    "volumetria_distintos.orderBy(\"distinto\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d170e036",
   "metadata": {},
   "source": [
    "**Versão em SQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7384903c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+-----------------------+\n",
      "|total|volumetria_pedidos|volumetria_pedidos_perc|\n",
      "+-----+------------------+-----------------------+\n",
      "|1    |88863             |90.06                  |\n",
      "|2    |7516              |7.62                   |\n",
      "|3    |1322              |1.34                   |\n",
      "|4    |505               |0.51                   |\n",
      "|5    |204               |0.21                   |\n",
      "+-----+------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+-------------------+-------------------------+\n",
      "|distinto|volumetria_distinto|volumetria_distintos_perc|\n",
      "+--------+-------------------+-------------------------+\n",
      "|1       |95430              |96.72                    |\n",
      "|2       |2846               |2.88                     |\n",
      "|3       |298                |0.30                     |\n",
      "|4       |70                 |0.07                     |\n",
      "|5       |8                  |0.01                     |\n",
      "+--------+-------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query base para as consultas\n",
    "olist_order_items.createOrReplaceTempView(\"order_items\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TEMP VIEW produtos AS\n",
    "    SELECT \n",
    "        order_id,\n",
    "        COUNT(product_id) AS total,\n",
    "        COUNT(DISTINCT product_id) AS distinto\n",
    "    FROM order_items\n",
    "    GROUP BY order_id\n",
    "\"\"\")\n",
    "\n",
    "#Visão total de pedidos\n",
    "volumetria = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        total,\n",
    "        COUNT(*) AS volumetria_pedidos,\n",
    "        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) AS volumetria_pedidos_perc\n",
    "    FROM produtos\n",
    "    GROUP BY total\n",
    "    ORDER BY total\n",
    "\"\"\")\n",
    "volumetria.show(5, truncate=False)\n",
    "\n",
    "#Visão total distintos\n",
    "volumetria_distintos = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        distinto,\n",
    "        COUNT(*) AS volumetria_distinto,\n",
    "        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) AS volumetria_distintos_perc\n",
    "    FROM produtos\n",
    "    GROUP BY distinto\n",
    "    ORDER BY distinto\n",
    "\"\"\")\n",
    "volumetria_distintos.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "215b53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_de_pedidos_com_unico_produto = produtos.filter(F.col(\"distinto\") == 1).select(\"order_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb0049",
   "metadata": {},
   "source": [
    "- Aproximadamente 90% dos pedidos realizados que contém apenas um produto e 7% que contém 2 produtos.\n",
    "- Aproximadamente 96% dos pedidos tem o mesmo produto enquanto 4% possuiam produtos diferentes.\n",
    "- Como 96% da base consiste em pedidos com o mesmo produto, será possível utilizar o order_id como uma proxy para o produto, já que as bases da Olist não possuem a avalição feita por produto, mas apenas por pedido.\n",
    "- Tendo essa informação, podemos gerar uma lista de order_id que pedidos que contém um item únicos ou vários itens iguais para utilizarmos no modelo de recomeção de outros produtos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d459cef9",
   "metadata": {},
   "source": [
    "---\n",
    "# **Verificando a volumetria de notas para cada pedido**\n",
    "\n",
    "Nessa seção, vamos investigar os dados sobre outra ótica. Agora vamos verificar a viabilidade dos datasets sobre a quantidade de avaliações realizadas para esses pedidos da lista de order_id gerada na seção anterior. Assim podemos conferir se houve avaliações o suficiente para que seja confiável o uso dessa base para treinar o modelo de recomendação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7158a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opção para um dataset pequeno\n",
    "lista_ids = [row['order_id'] for row in lista_de_pedidos_com_unico_produto.collect()]\n",
    "df_produtos = olist_orders.filter(F.col(\"order_id\").isin(lista_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b4fef6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95430, 99441)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Opção para um dataset grande\n",
    "df_produtos = olist_orders.join(lista_de_pedidos_com_unico_produto, on=\"order_id\", how=\"inner\")\n",
    "df_produtos.count(), olist_orders.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7680614e",
   "metadata": {},
   "source": [
    "Além de filtra o dataset **olist_orders** com a lista de order_ids da primeira seção, vamos também filtrar a base para pegarmos apenas os pedidos que tenham o **status como entregue**. Optei por essa forma para apenas utilizarmos apenas avaliações de produtos que foram devidamente entregues e consequentemente avaliados pelos os usuários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70098641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93281, 95430, 99441)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtrando os order_id que estão dentro da lista de pedidos com único tipo de produto\n",
    "df_produtos_entregues = df_produtos.filter(F.col(\"order_status\") == \"delivered\").select(\"customer_id\", \"order_id\")\n",
    "\n",
    "#Comparando a qtd de linhas\n",
    "df_produtos_entregues.count(), df_produtos.count(), olist_orders.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ca5fc4",
   "metadata": {},
   "source": [
    "Um fator importante sobre os datasets é que na base **olist_customers** existe dois IDs de usuários diferentes, um que único e outros que é usado para a conexão com as demais bases. Vamos fazer o cruzamento desse dataset com o nosso dataset atual para utilizarmos a coluna de **customer_unique_id** ao invés da coluna **customer_id**. Além de cruzar com o dataset **olist_order_reviws** para obtermos as avaliações feitas desses pedidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c776080a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+\n",
      "|            order_id|  customer_unique_id|review_score|\n",
      "+--------------------+--------------------+------------+\n",
      "|98c78522be2bccf4c...|62aad23fbe0be06a5...|           5|\n",
      "|bec5a824282dde8cd...|5570e312bd641ceba...|           5|\n",
      "|c5f30bdd01bc931c0...|c09049ee8be260854...|           5|\n",
      "|8dede9c6014be218c...|b08fab27d47a1eb6d...|           5|\n",
      "|b23f8178f3b6555a7...|86c7ca0abbc14188b...|           5|\n",
      "+--------------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cruzamentos\n",
    "df_produtos_avaliacoes = df_produtos_entregues.join(olist_customers, on=\"customer_id\", how=\"inner\") \\\n",
    "                                              .join(olist_order_reviews, on=\"order_id\", how=\"left\")\n",
    "df_produtos_avaliacoes = df_produtos_avaliacoes.drop(\"customer_id\")\n",
    "df_produtos_avaliacoes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebed8e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------------+------------------+\n",
      "|order_id_nulos|customer_unique_id_nulos|review_score_nulos|\n",
      "+--------------+------------------------+------------------+\n",
      "|             0|                       0|               608|\n",
      "+--------------+------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Forma simples de verificar vazios\n",
    "df_produtos_avaliacoes.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(c + '_nulos') \n",
    "    for c in df_produtos_avaliacoes.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33d502d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------------+-------------------+-----+\n",
      "|order_id_isnull|customer_unique_id_isnull|review_score_isnull|count|\n",
      "+---------------+-------------------------+-------------------+-----+\n",
      "|false          |false                    |false              |93163|\n",
      "|false          |false                    |true               |608  |\n",
      "+---------------+-------------------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Forma mais complexa de verifica vazios\n",
    "df_produtos_avaliacoes_nulos = df_produtos_avaliacoes\n",
    "\n",
    "for c in df_produtos_avaliacoes.columns:\n",
    "    df_produtos_avaliacoes_nulos = df_produtos_avaliacoes_nulos.withColumn(\n",
    "        f\"{c}_isnull\", F.col(c).isNull()\n",
    "    )\n",
    "\n",
    "isnull_cols = [f\"{c}_isnull\" for c in df_produtos_avaliacoes.columns]\n",
    "\n",
    "df_produtos_avaliacoes_nulos.groupBy(isnull_cols).count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e34e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrando os pedidos que estão sem avaliações\n",
    "df_produtos_avaliacoes = df_produtos_avaliacoes.dropna(subset=[\"review_score\"], how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5d43785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando o nome das colunas\n",
    "colunas = {\n",
    "    'customer_unique_id':'user_id',\n",
    "    'order_id':'product_id',\n",
    "    'review_score':'rating'\n",
    "}\n",
    "\n",
    "for antigo, novo in colunas.items():\n",
    "    df_produtos_avaliacoes = df_produtos_avaliacoes \\\n",
    "                                .withColumnRenamed(antigo, novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a689e212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+------------------+\n",
      "|qtd_avaliacoes|qtd_usuarios|qtd_usuarios_perct|\n",
      "+--------------+------------+------------------+\n",
      "|             1|       87323|             97.11|\n",
      "|             2|        2154|               2.4|\n",
      "|             3|         310|              0.34|\n",
      "|             4|         101|              0.11|\n",
      "|             5|          22|              0.02|\n",
      "|             6|          11|              0.01|\n",
      "|             7|           1|               0.0|\n",
      "|            15|           1|               0.0|\n",
      "+--------------+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Comparando a quantidade de usuários e comparação a quantidade de avalições feitas\n",
    "avaliacoes_por_user_id = df_produtos_avaliacoes.groupBy(\"user_id\").agg(F.count(\"*\").alias(\"qtd_avaliacoes\"))\n",
    "usuarios_por_qtd_avaliacoes = avaliacoes_por_user_id.groupBy(\"qtd_avaliacoes\").agg(F.count(\"*\").alias(\"qtd_usuarios\"))\n",
    "window = Window.partitionBy()\n",
    "usuarios_por_qtd_avaliacoes = usuarios_por_qtd_avaliacoes.withColumn(\n",
    "    \"qtd_usuarios_perct\", F.round((F.col(\"qtd_usuarios\") / F.sum(\"qtd_usuarios\").over(window)) *100, 2))\n",
    "usuarios_por_qtd_avaliacoes.orderBy(F.col(\"qtd_avaliacoes\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af0f814d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------------+\n",
      "|pedidos|volumetria_usuarios|volumetria_usuarios_perc|\n",
      "+-------+-------------------+------------------------+\n",
      "|      1|              87323|                   97.11|\n",
      "|      2|               2154|                     2.4|\n",
      "|      3|                310|                    0.34|\n",
      "|      4|                101|                    0.11|\n",
      "|      5|                 22|                    0.02|\n",
      "|      6|                 11|                    0.01|\n",
      "|      7|                  1|                     0.0|\n",
      "|     15|                  1|                     0.0|\n",
      "+-------+-------------------+------------------------+\n",
      "\n",
      "+--------------+-------------------+------------------------+\n",
      "|avaliacoes_avg|volumetria_usuarios|volumetria_usuarios_perc|\n",
      "+--------------+-------------------+------------------------+\n",
      "|           1.0|               8155|                    9.07|\n",
      "|           2.0|               2640|                    2.94|\n",
      "|           3.0|               7449|                    8.28|\n",
      "|           4.0|              18020|                   20.04|\n",
      "|           5.0|              53659|                   59.67|\n",
      "+--------------+-------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Base para os cálculos\n",
    "window = Window.partitionBy()\n",
    "usuarios = df_produtos_avaliacoes.groupBy(\"user_id\").agg(F.count(\"product_id\").alias(\"pedidos\"),\n",
    "                                                         F.count(\"rating\").alias(\"avaliacoes\"),\n",
    "                                                         F.round(F.mean(\"rating\"), 0).alias(\"avaliacoes_avg\"))\n",
    "\n",
    "#Visão de volumetria de usuários pela quantidade de pedidos\n",
    "usuarios_df = usuarios.groupBy(\"pedidos\").agg(F.count(\"*\").alias(\"volumetria_usuarios\"))\n",
    "usuarios_df = usuarios_df.withColumn(\n",
    "    \"volumetria_usuarios_perc\", F.round((F.col(\"volumetria_usuarios\") / F.sum(\"volumetria_usuarios\").over(window)) *100, 2))\n",
    "usuarios_df.orderBy(\"pedidos\").show()\n",
    "\n",
    "#Visão de volumetria de usuários pela quantidade média da nota\n",
    "usuarios_df = usuarios.groupBy(\"avaliacoes_avg\").agg(F.count(\"*\").alias(\"volumetria_usuarios\"))\n",
    "usuarios_df = usuarios_df.withColumn(\n",
    "    \"volumetria_usuarios_perc\", F.round(F.col(\"volumetria_usuarios\") / F.sum(\"volumetria_usuarios\").over(window) *100, 2))\n",
    "usuarios_df.orderBy(\"avaliacoes_avg\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ba11f",
   "metadata": {},
   "source": [
    "**Versão SQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20520289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+------------------+\n",
      "|qtd_avaliacoes|qtd_usuarios|qtd_usuarios_perct|\n",
      "+--------------+------------+------------------+\n",
      "|             1|       87323|             97.11|\n",
      "|             2|        2154|               2.4|\n",
      "|             3|         310|              0.34|\n",
      "|             4|         101|              0.11|\n",
      "|             5|          22|              0.02|\n",
      "|             6|          11|              0.01|\n",
      "|             7|           1|               0.0|\n",
      "|            15|           1|               0.0|\n",
      "+--------------+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query base para as consultas\n",
    "df_produtos_avaliacoes.createOrReplaceTempView(\"produtos_avaliacoes\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TEMP VIEW avaliacoes_por_user_id AS\n",
    "    SELECT user_id,\n",
    "        COUNT(*) AS qtd_avaliacoes\n",
    "    FROM produtos_avaliacoes\n",
    "    GROUP BY user_id\n",
    "\"\"\")\n",
    "\n",
    "#Comparando a quantidade de usuários e comparação a quantidade de avalições feitas\n",
    "resultado = spark.sql(\"\"\"\n",
    "    SELECT qtd_avaliacoes,\n",
    "        COUNT(*) AS qtd_usuarios,\n",
    "        ROUND(COUNT(*) *100 / SUM(COUNT(*)) OVER(), 2) AS qtd_usuarios_perct\n",
    "    FROM avaliacoes_por_user_id\n",
    "    GROUP BY qtd_avaliacoes\n",
    "    ORDER BY qtd_avaliacoes\n",
    "\"\"\")\n",
    "\n",
    "resultado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79387c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------------+\n",
      "|pedidos|volumetria_usuarios|volumetria_usuarios_perc|\n",
      "+-------+-------------------+------------------------+\n",
      "|      1|              87323|                   97.11|\n",
      "|      2|               2154|                     2.4|\n",
      "|      3|                310|                    0.34|\n",
      "|      4|                101|                    0.11|\n",
      "|      5|                 22|                    0.02|\n",
      "|      6|                 11|                    0.01|\n",
      "|      7|                  1|                     0.0|\n",
      "|     15|                  1|                     0.0|\n",
      "+-------+-------------------+------------------------+\n",
      "\n",
      "+--------------+-------------------+------------------------+\n",
      "|avaliacoes_avg|volumetria_usuarios|volumetria_usuarios_perc|\n",
      "+--------------+-------------------+------------------------+\n",
      "|           1.0|               8155|                    9.07|\n",
      "|           2.0|               2640|                    2.94|\n",
      "|           3.0|               7449|                    8.28|\n",
      "|           4.0|              18020|                   20.04|\n",
      "|           5.0|              53659|                   59.67|\n",
      "+--------------+-------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query base para as consultas\n",
    "df_produtos_avaliacoes.createOrReplaceTempView(\"usuarios\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TEMP VIEW usuarios_df AS\n",
    "    SELECT user_id,\n",
    "          COUNT(product_id) AS pedidos,\n",
    "          COUNT(rating) AS avaliacoes,\n",
    "          ROUND(MEAN(rating), 0) AS avaliacoes_avg\n",
    "    FROM usuarios\n",
    "    GROUP BY user_id\n",
    "\"\"\")\n",
    "\n",
    "#Visão de volumetria de usuários pela quantidade de pedidos\n",
    "resultado = spark.sql(\"\"\"\n",
    "    SELECT pedidos,\n",
    "          COUNT(*) AS volumetria_usuarios,\n",
    "          ROUND(COUNT(*) * 100 / SUM(COUNT(*)) OVER(), 2) AS volumetria_usuarios_perc\n",
    "    FROM usuarios_df\n",
    "    GROUP BY pedidos\n",
    "    ORDER BY pedidos\n",
    "\"\"\")\n",
    "resultado.show()\n",
    "\n",
    "#Visão de volumetria de usuários pela quantidade média da nota\n",
    "resultado = spark.sql(\"\"\"\n",
    "    SELECT avaliacoes_avg,\n",
    "          COUNT(*) AS volumetria_usuarios,\n",
    "          ROUND(COUNT(*) * 100 / SUM(COUNT(*)) OVER(), 2) AS volumetria_usuarios_perc\n",
    "    FROM usuarios_df\n",
    "    GROUP BY avaliacoes_avg\n",
    "    ORDER BY avaliacoes_avg\n",
    "\"\"\")\n",
    "resultado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db76780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando as notas normilizadas\n",
    "user_window = Window.partitionBy(\"user_id\")\n",
    "\n",
    "df_produtos_avaliacoes = df_produtos_avaliacoes.withColumn(\n",
    "    \"user_mean\", F.avg(\"rating\").over(user_window))\n",
    "df_produtos_avaliacoes = df_produtos_avaliacoes.withColumn(\n",
    "    \"user_reviews_count\", F.count(\"rating\").over(user_window))\n",
    "df_produtos_avaliacoes = df_produtos_avaliacoes.withColumn(\n",
    "    \"normalized_rating\", F.col(\"rating\") - F.col(\"user_mean\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c55f4",
   "metadata": {},
   "source": [
    "- Aproximadamente 97% dos usuários fizeram um único pedido.\n",
    "- Numa escala de nota de 1 a 5: aproximadamente 12% dos usuários deram uma nota baixa para o produto (1 ou 2), 8% deram uma nota mediana (3) e 80% deram uma nota alta (4 ou 5).\n",
    "- Mesmo com 97% dos usuários tendo um pedido, vamos no modelo testar tanto o valor absoluto da média de notas quanto os valores normalizado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
